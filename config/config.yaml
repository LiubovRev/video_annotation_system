
---

# 2️⃣ `config.yaml` (Best-Practice Version)

```yaml
# =============================================================================
# config.yaml
# Video Annotation System - Central Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# Directories
# -----------------------------------------------------------------------------
directories:
  raw_video_root: "data/raw"
  processed_data_dir: "data/processed"
  annotations_dir: "data/annotations"
  output_dir: "outputs"
  models_dir: "models"


# -----------------------------------------------------------------------------
# Pipeline Flags
# -----------------------------------------------------------------------------
flags:
  skip_video_processing:      false
  skip_pose_extraction:       false
  skip_pose_clustering:       true
  skip_annotation_processing: false
  force_recombine:            false

# -----------------------------------------------------------------------------
# Video Processing (Step 1)
# -----------------------------------------------------------------------------
video_processing:
  raw_video_filename: "camera_a.mkv"
  fps:                15
  step_size:          1
  nb_objects:         2
  yolo_model:         "yolo11m.pt"
  model_size:         "small"
  object_class:       0
  device:             "cuda"

# -----------------------------------------------------------------------------
# Pose Extraction (Step 2)
# -----------------------------------------------------------------------------
pose_extraction:
  directory:    "PosesDir"
  abs_base:     0
  fps:          15
  id_to_label:
    "1": "Therapist1"
    "2": "Patient1"

# -----------------------------------------------------------------------------
# Pose Clustering (Step 3, optional)
# -----------------------------------------------------------------------------
pose_clustering:
  movement_threshold:   10
  proximity_close:      200
  proximity_medium:     400
  response_window:      5
  confidence_threshold: 0.5
  smooth_window:        11
  smooth_poly:          3
  k_range:              [2, 8]
  phase_window:         30
  n_phases:             4
  therapist_label:      "Therapist"
  child_label:          "Child"

# -----------------------------------------------------------------------------
# Annotation Alignment (Step 4)
# -----------------------------------------------------------------------------
annotation_alignment:
  features_subdir:    "PosesDir"
  columns_to_drop:    ["time_min:s.ms"]
  label_prefix_map:
    "C": "Child"
    "T": "Therapist"
  auto_trim_buffer:   5      # seconds before/after first/last annotation

# -----------------------------------------------------------------------------
# Project Trim Times (Optional)
# -----------------------------------------------------------------------------
trim_times: {}           # leave empty, auto-computed if not provided
default_trim: [0, null, 15]

# -----------------------------------------------------------------------------
# Label Map
# -----------------------------------------------------------------------------
label_map:
  0:  "C"
  1:  "CCR"
  2:  "CHO"
  3:  "CSI"
  4:  "CST"
  5:  "T"
  6:  "TC"
  7:  "TRE"
  8:  "TSI"
  9:  "TST"

# -----------------------------------------------------------------------------
# Model Configuration
# -----------------------------------------------------------------------------
model:
  file:          "models/model_xgboost.joblib"
  features_file: "models/feature_names.json"
  fps:           15

# -----------------------------------------------------------------------------
# Model Training (Step 5)
# -----------------------------------------------------------------------------
model_training:
  min_samples_per_class: 30
  test_size:             0.2
  n_iter_search:         50
  non_posture_classes:   ["vocalizations", "unlabeled"]

# -----------------------------------------------------------------------------
# Prediction (Step 6)
# -----------------------------------------------------------------------------
predict:
  data_path: null   # single-project path or null for batch mode

# -----------------------------------------------------------------------------
# Plotting
# -----------------------------------------------------------------------------
plotting:
  dpi:                 300
  figsize_per_project: [18, 10]
  figsize_global:      [24, 12]
  colormap:            "viridis"
